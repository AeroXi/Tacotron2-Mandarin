{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pinyin\n",
    "import soundfile as sf\n",
    "import torch\n",
    "\n",
    "from config import sampling_rate\n",
    "from models.layers import STFT\n",
    "from models.models import Tacotron2\n",
    "from utils import text_to_sequence, ensure_folder, plot_data, HParams\n",
    "\n",
    "\n",
    "class Denoiser(torch.nn.Module):\n",
    "    \"\"\" Removes model bias from audio produced with waveglow \"\"\"\n",
    "\n",
    "    def __init__(self, waveglow, filter_length=1024, n_overlap=4,\n",
    "                 win_length=1024, mode='zeros'):\n",
    "        super(Denoiser, self).__init__()\n",
    "        self.stft = STFT(filter_length=filter_length,\n",
    "                         hop_length=int(filter_length / n_overlap),\n",
    "                         win_length=win_length).cuda()\n",
    "        if mode == 'zeros':\n",
    "            mel_input = torch.zeros(\n",
    "                (1, 80, 88),\n",
    "                dtype=waveglow.upsample.weight.dtype,\n",
    "                device=waveglow.upsample.weight.device)\n",
    "        elif mode == 'normal':\n",
    "            mel_input = torch.randn(\n",
    "                (1, 80, 88),\n",
    "                dtype=waveglow.upsample.weight.dtype,\n",
    "                device=waveglow.upsample.weight.device)\n",
    "        else:\n",
    "            raise Exception(\"Mode {} if not supported\".format(mode))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            bias_audio = waveglow.infer(mel_input, sigma=0.0).float()\n",
    "            bias_spec, _ = self.stft.transform(bias_audio)\n",
    "\n",
    "        self.register_buffer('bias_spec', bias_spec[:, :, 0][:, :, None])\n",
    "\n",
    "    def forward(self, audio, strength=0.1):\n",
    "        audio_spec, audio_angles = self.stft.transform(audio.cuda().float())\n",
    "        audio_spec_denoised = audio_spec - self.bias_spec * strength\n",
    "        audio_spec_denoised = torch.clamp(audio_spec_denoised, 0.0)\n",
    "        audio_denoised = self.stft.inverse(audio_spec_denoised, audio_angles)\n",
    "        return audio_denoised\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    config = HParams()\n",
    "    checkpoint = 'tacotron2-cn.pt'\n",
    "    print('loading model: {}...'.format(checkpoint))\n",
    "    model = Tacotron2(config)\n",
    "    model.load_state_dict(torch.load(checkpoint))\n",
    "    model = model.to('cpu')\n",
    "    model.eval()\n",
    "\n",
    "    waveglow_path = 'waveglow_256channels.pt'\n",
    "    waveglow = torch.load(waveglow_path)['model']\n",
    "    waveglow.cuda().eval().half()\n",
    "    for k in waveglow.convinv:\n",
    "        k.float()\n",
    "    denoiser = Denoiser(waveglow)\n",
    "\n",
    "    text = input(\"请输入语句：\")\n",
    "    text = pinyin.get(text, format=\"numerical\", delimiter=\" \")\n",
    "    print(text)\n",
    "    sequence = np.array(text_to_sequence(text))[None, :]\n",
    "    sequence = torch.autograd.Variable(torch.from_numpy(sequence)).long()\n",
    "\n",
    "    mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence)\n",
    "    plot_data((mel_outputs.float().data.cpu().numpy()[0],\n",
    "               mel_outputs_postnet.float().data.cpu().numpy()[0],\n",
    "               alignments.float().data.cpu().numpy()[0].T))\n",
    "\n",
    "    ensure_folder('images')\n",
    "    plt.savefig('images/mel_spec.jpg')\n",
    "\n",
    "    mel_outputs_postnet = mel_outputs_postnet.type(torch.float16)\n",
    "    with torch.no_grad():\n",
    "        audio = waveglow.infer(mel_outputs_postnet.cuda(), sigma=0.666)\n",
    "\n",
    "    audio = audio[0].data.cpu().numpy()\n",
    "    audio = audio.astype(np.float32)\n",
    "\n",
    "    print('audio.shape: ' + str(audio.shape))\n",
    "    print(audio)\n",
    "\n",
    "    sf.write('output.wav', audio, sampling_rate, 'PCM_24')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.display.Audio(\"output.wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
